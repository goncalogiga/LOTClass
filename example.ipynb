{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe06197-db3c-447d-93b0-2eec9f225716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'LOTClass' already exists and is not an empty directory.\n",
      "\u001b[31mERROR: Directory 'LOTClass/.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n",
      "Requirement already satisfied: transformers in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (4.12.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: filelock in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: requests in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: click in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /home/goncalo/anaconda3/envs/pi_env/lib/python3.8/site-packages (0.1.95)\n"
     ]
    }
   ],
   "source": [
    "# If Colab\n",
    "!git clone https://github.com/goncalogiga/LOTClass\n",
    "!pip install LOTClass/.\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad29c068-c682-40cf-9854-b08248791db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open cleaned_mails.zip, cleaned_mails.zip.zip or cleaned_mails.zip.ZIP.\n",
      "unzip:  cannot find or open cleaned_mails_labeled.zip, cleaned_mails_labeled.zip.zip or cleaned_mails_labeled.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# If Colab -> load the mails as zips\n",
    "!unzip cleaned_mails.zip\n",
    "!unzip cleaned_mails_labeled.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e074ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "train_set = pd.read_csv(\"data/cleaned_mails.csv\")\n",
    "test_set = pd.read_csv(\"data/cleaned_mails_labeled.csv\")\n",
    "test_set = test_set[(test_set[\"Catégorie\"] != \"Réclamation\") & (test_set[\"Catégorie\"] != \"Déménagement\") & (test_set[\"Catégorie\"] != \"Contrat – Coordonnées personnelles\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40deb484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/goncalo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1425a900-40a6-4a1c-80a5-88d1cb43e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LOTClass.french.LOTClassModel import LOTClassifier\n",
    "from LOTClass.french.config import LOTClassConfig\n",
    "\n",
    "labels = [\n",
    "          ['releve compteur'], \n",
    "          ['espace client'], \n",
    "          ['facture factures montant mensualisation virement virements bancaire bancaires']\n",
    "  ]\n",
    "\n",
    "args = LOTClassConfig(overwrite_dataset=True, train_batch_size=4, gpus=1, \n",
    "                      eval_batch_size=4, accum_steps=32,\n",
    "                      test_file=\"test_file.txt\", \n",
    "                      test_label_file=\"test_label_file.txt\")\n",
    "\n",
    "model = LOTClassifier(path=\"datasets/mails/\", labels=labels, \n",
    "                      args=args)\n",
    "\n",
    "X_test = test_set[\"Corps\"]\n",
    "y_test = test_set[\"Catégorie\"]\n",
    "\n",
    "model.build_test_dataset(list(X_test), list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95b8998-c9ff-42d4-be6d-0823e76b4b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n'arrive joindre car mes horaires travail sont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comme voici retour courriel justificatif maria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chere cher serions reconnaissantes vouloir pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pouvez passe cela fait fois j'essaie connecter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>espace suis actuellement titulaire abonnements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>voici semaines m'a ete receptionne petite mais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>électronique voila clair maintenant effet sach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>voudrais informer vais quitter appartement sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>recu facture annuelle souhaiterai comprendre p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>prie trouver cijoint mes coordonnees bancaires...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Corps\n",
       "0    n'arrive joindre car mes horaires travail sont...\n",
       "1    comme voici retour courriel justificatif maria...\n",
       "2    chere cher serions reconnaissantes vouloir pro...\n",
       "3    pouvez passe cela fait fois j'essaie connecter...\n",
       "4    espace suis actuellement titulaire abonnements...\n",
       "..                                                 ...\n",
       "574  voici semaines m'a ete receptionne petite mais...\n",
       "575  électronique voila clair maintenant effet sach...\n",
       "576  voudrais informer vais quitter appartement sou...\n",
       "577  recu facture annuelle souhaiterai comprendre p...\n",
       "578  prie trouver cijoint mes coordonnees bancaires...\n",
       "\n",
       "[579 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b458fa8e-323c-4d63-9f63-3a43c9b3296c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corps</th>\n",
       "      <th>Catégorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comme voici retour courriel justificatif maria...</td>\n",
       "      <td>Espace client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>espace suis actuellement titulaire abonnements...</td>\n",
       "      <td>Espace client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facture recu document cependant pensais factur...</td>\n",
       "      <td>Relève de compteur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bonsoir virement facture ref ete virement banc...</td>\n",
       "      <td>Facture – Paiement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>voici l'index releve jour bonne</td>\n",
       "      <td>Relève de compteur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>mes factures soient car certaines sommes sont ...</td>\n",
       "      <td>Facture – Paiement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>compte internet avoir reussi creer compte pers...</td>\n",
       "      <td>Espace client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>numéro ecris concernant nos locataire locatair...</td>\n",
       "      <td>Relève de compteur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>viens d'emmenager souscrire internet depuis se...</td>\n",
       "      <td>Espace client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>recu facture annuelle souhaiterai comprendre p...</td>\n",
       "      <td>Facture – Paiement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Corps           Catégorie\n",
       "1    comme voici retour courriel justificatif maria...       Espace client\n",
       "3    espace suis actuellement titulaire abonnements...       Espace client\n",
       "4    facture recu document cependant pensais factur...  Relève de compteur\n",
       "7    bonsoir virement facture ref ete virement banc...  Facture – Paiement\n",
       "9                     voici l'index releve jour bonne   Relève de compteur\n",
       "..                                                 ...                 ...\n",
       "279  mes factures soient car certaines sommes sont ...  Facture – Paiement\n",
       "280  compte internet avoir reussi creer compte pers...       Espace client\n",
       "281  numéro ecris concernant nos locataire locatair...  Relève de compteur\n",
       "282  viens d'emmenager souscrire internet depuis se...       Espace client\n",
       "292  recu facture annuelle souhaiterai comprendre p...  Facture – Paiement\n",
       "\n",
       "[122 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb75963a-923a-4bec-96f3-2708a778c042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective training batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 792k/792k [00:01<00:00, 791kB/s]\n",
      "Downloading: 100%|██████████| 1.33M/1.33M [00:01<00:00, 947kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names used for each class are: {0: ['releve', 'compteur'], 1: ['espace', 'client'], 2: ['facture', 'factures', 'montant', 'mensualisation', 'virement', 'virements', 'bancaire', 'bancaires']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at camembert-base were not used when initializing LOTClassModel: ['roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'lm_head.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.query.bias']\n",
      "- This IS expected if you are initializing LOTClassModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LOTClassModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LOTClassModel were not initialized from the model checkpoint at camembert-base and are newly initialized: ['encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'cls.layer_norm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'cls.layer_norm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'cls.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'cls.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'cls.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.weight', 'dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'cls.decoder.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'cls.decoder.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'classifier.bias', 'encoder.layer.5.intermediate.dense.bias', 'classifier.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading texts from datasets/mails/train.txt\n",
      "Converting texts into tensors.\n"
     ]
    }
   ],
   "source": [
    "model.fit(list(train_set[\"Corps\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e12c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = model.classification_report(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1059605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dbd43346cf4060a7c5249e62daf2cb2395365dab3b14076ef7b34680f245741"
  },
  "kernelspec": {
   "display_name": "pi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
